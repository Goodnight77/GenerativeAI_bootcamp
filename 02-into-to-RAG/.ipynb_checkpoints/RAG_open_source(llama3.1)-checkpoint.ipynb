{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1K5u1xyfHBG0NmB2OwLz0U-bQqwnwQkB3\n",
    "\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import dotenv_values \n",
    "secrets_dir= os.path.expanduser(\"~/developer/.secrets\")\n",
    "\n",
    "config = {\n",
    "    **dotenv_values(secrets_dir + \"/.env\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HF_API_KEY': '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',\n",
       " 'QDRANT_API_KEY': '24d1oegCPQYy5k7cI9HEH9pgEXkn0vaBENA3OZ0MZ7z-uGSKnkXn9Q',\n",
       " 'COHERE_API_KEY': '9kao1BvUKVReawuT9iKZTx1Vv0HmwY3YeFuZXmuJ',\n",
       " 'LANGCHAIN_API_KEY': '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',\n",
       " 'GROQ_API_KEY': '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'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(config.get(\"HF_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groq : 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 huggingface: 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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(os.path.expanduser('~/developer/.secrets/.env'))\n",
    "\n",
    "# Access the secrets\n",
    "GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
    "HF_API_KEY = os.getenv('HF_API_KEY')\n",
    "\n",
    "\n",
    "print(f\"groq : {GROQ_API_KEY} huggingface: {HF_API_KEY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/goodnight/miniconda3/envs/gnn/bin/python'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "environ{'DOCKER_BUILDKIT': '1',\n",
       "        'ENABLE_DYNAMIC_INSTALL': 'true',\n",
       "        'LESSOPEN': '| /usr/bin/lesspipe %s',\n",
       "        'GITHUB_TOKEN': 'ghu_KBOggJhC9wIG1MNdrSA3sMnUYCGUkW2V8vuY',\n",
       "        'PYTHONIOENCODING': 'UTF-8',\n",
       "        'GITHUB_CODESPACE_TOKEN': 'A4BSVDGYK6AOWL2BL74C5P3HJD32BANCNFSM4AKU2EZA',\n",
       "        'USER': 'codespace',\n",
       "        'RVM_PATH': '/usr/local/rvm',\n",
       "        'NVS_ROOT': '/usr/local/nvs',\n",
       "        'HOSTNAME': 'codespaces-c24181',\n",
       "        'DOTNET_USE_POLLING_FILE_WATCHER': 'true',\n",
       "        'CONDA_SCRIPT': '/opt/conda/etc/profile.d/conda.sh',\n",
       "        'PIPX_HOME': '/usr/local/py-utils',\n",
       "        'SHLVL': '2',\n",
       "        'GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN': 'app.github.dev',\n",
       "        'HUGO_ROOT': '/home/codespace/.hugo',\n",
       "        'HOME': '/home/codespace',\n",
       "        'OLDPWD': '/',\n",
       "        'ORYX_ENV_TYPE': 'vsonline-present',\n",
       "        'NVM_BIN': '/usr/local/share/nvm/versions/node/v20.17.0/bin',\n",
       "        'CODESPACES': 'true',\n",
       "        'DOTNET_RUNNING_IN_CONTAINER': 'true',\n",
       "        'NVM_SYMLINK_CURRENT': 'true',\n",
       "        'DYNAMIC_INSTALL_ROOT_DIR': '/opt',\n",
       "        'PIPX_BIN_DIR': '/usr/local/py-utils/bin',\n",
       "        'NVM_INC': '/usr/local/share/nvm/versions/node/v20.17.0/include/node',\n",
       "        'rvm_stored_umask': '0022',\n",
       "        'ORYX_DIR': '/usr/local/oryx',\n",
       "        'GRADLE_HOME': '/usr/local/sdkman/candidates/gradle/current',\n",
       "        'JUPYTERLAB_PATH': '/home/codespace/.local/bin',\n",
       "        'rvm_user_install_flag': '0',\n",
       "        'MAVEN_HOME': '/usr/local/sdkman/candidates/maven/current',\n",
       "        'GOROOT': '/usr/local/go',\n",
       "        'NODE_ROOT': '/home/codespace/nvm',\n",
       "        'GITHUB_GRAPHQL_URL': 'https://api.github.com/graphql',\n",
       "        'GITHUB_USER': 'Goodnight77',\n",
       "        'NVM_DIR': '/usr/local/share/nvm',\n",
       "        'PYTHON_PATH': '/usr/local/python/current',\n",
       "        'DOTNET_SKIP_FIRST_TIME_EXPERIENCE': '1',\n",
       "        'ContainerVersion': '13',\n",
       "        'NVS_HOME': '/usr/local/nvs',\n",
       "        'GITHUB_API_URL': 'https://api.github.com',\n",
       "        'rvm_bin_path': '/usr/local/rvm/bin',\n",
       "        'SDKMAN_CANDIDATES_API': 'https://api.sdkman.io/2',\n",
       "        '_': '/opt/conda/envs/mini_rag/bin/python',\n",
       "        'RUBY_VERSION': 'ruby-3.3.4',\n",
       "        'PROMPT_DIRTRIM': '4',\n",
       "        'IRBRC': '/usr/local/rvm/rubies/ruby-3.3.4/.irbrc',\n",
       "        'CLOUDENV_ENVIRONMENT_ID': '12b7259d-e6ed-476b-9015-ffca0b7e6d1b',\n",
       "        'DOTNET_ROOT': '/usr/share/dotnet',\n",
       "        'NVS_DIR': '/usr/local/nvs',\n",
       "        'PHP_ROOT': '/home/codespace/.php',\n",
       "        'PATH': '/opt/conda/envs/mini_rag/bin:/opt/conda/condabin:/vscode/bin/linux-x64/f1a4fb101478ce6ec82fe9627c43efbf9e98c813/bin/remote-cli:/home/codespace/.local/bin:/home/codespace/.dotnet:/home/codespace/nvm/current/bin:/home/codespace/.php/current/bin:/home/codespace/.python/current/bin:/home/codespace/java/current/bin:/home/codespace/.ruby/current/bin:/home/codespace/.local/bin:/usr/local/python/current/bin:/usr/local/py-utils/bin:/usr/local/oryx:/usr/local/go/bin:/go/bin:/usr/local/sdkman/bin:/usr/local/sdkman/candidates/java/current/bin:/usr/local/sdkman/candidates/gradle/current/bin:/usr/local/sdkman/candidates/maven/current/bin:/usr/local/sdkman/candidates/ant/current/bin:/usr/local/rvm/gems/default/bin:/usr/local/rvm/gems/default@global/bin:/usr/local/rvm/rubies/default/bin:/usr/local/share/rbenv/bin:/usr/local/php/current/bin:/opt/conda/bin:/usr/local/nvs:/usr/local/share/nvm/current/bin:/usr/local/hugo/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/share/dotnet:/home/codespace/.dotnet/tools:/usr/local/rvm/bin',\n",
       "        'JAVA_ROOT': '/home/codespace/java',\n",
       "        'VSCODE_AGENT_FOLDER': '/home/codespace/.vscode-remote',\n",
       "        'SDKMAN_CANDIDATES_DIR': '/usr/local/sdkman/candidates',\n",
       "        'HUGO_DIR': '/usr/local/hugo/bin',\n",
       "        'NPM_GLOBAL': '/home/codespace/.npm-global',\n",
       "        'SHELL_LOGGED_IN': 'true',\n",
       "        'MY_RUBY_HOME': '/usr/local/rvm/rubies/ruby-3.3.4',\n",
       "        'LANG': 'C.UTF-8',\n",
       "        'SDKMAN_DIR': '/usr/local/sdkman',\n",
       "        'RUBY_ROOT': '/home/codespace/.ruby',\n",
       "        'LS_COLORS': '',\n",
       "        'SDKMAN_PLATFORM': 'linuxx64',\n",
       "        'GITHUB_REPOSITORY': 'Goodnight77/GenerativeAI_bootcamp',\n",
       "        'SHELL': '/bin/bash',\n",
       "        'GOPATH': '/go',\n",
       "        'rvm_prefix': '/usr/local',\n",
       "        'rvm_loaded_flag': '1',\n",
       "        'GEM_HOME': '/usr/local/rvm/gems/ruby-3.3.4',\n",
       "        'ORYX_PREFER_USER_INSTALLED_SDKS': 'true',\n",
       "        'LESSCLOSE': '/usr/bin/lesspipe %s %s',\n",
       "        'ORYX_SDK_STORAGE_BASE_URL': 'https://oryx-cdn.microsoft.io',\n",
       "        'CONDA_DIR': '/opt/conda',\n",
       "        'rvm_version': '1.29.12 (latest)',\n",
       "        'DEBIAN_FLAVOR': 'focal-scm',\n",
       "        'GEM_PATH': '/usr/local/rvm/gems/ruby-3.3.4:/usr/local/rvm/gems/ruby-3.3.4@global',\n",
       "        'JAVA_HOME': '/usr/local/sdkman/candidates/java/current',\n",
       "        'NVS_USE_XZ': '1',\n",
       "        'INTERNAL_VSCS_TARGET_URL': 'https://westeurope.online.visualstudio.com',\n",
       "        'PWD': '/vscode/bin/linux-x64/f1a4fb101478ce6ec82fe9627c43efbf9e98c813',\n",
       "        'NVM_CD_FLAGS': '',\n",
       "        'GITHUB_SERVER_URL': 'https://github.com',\n",
       "        'PHP_PATH': '/usr/local/php/current',\n",
       "        'PYTHON_ROOT': '/home/codespace/.python',\n",
       "        'RAILS_DEVELOPMENT_HOSTS': '.githubpreview.dev,.preview.app.github.dev,.app.github.dev',\n",
       "        'NVS_OS': 'linux',\n",
       "        'CODESPACE_NAME': 'fluffy-tribble-56gv664wg9927vp4',\n",
       "        'RUBY_HOME': '/usr/local/rvm/rubies/default',\n",
       "        'MAVEN_ROOT': '/home/codespace/.maven',\n",
       "        'rvm_path': '/usr/local/rvm',\n",
       "        'NUGET_XMLDOC_MODE': 'skip',\n",
       "        'VSCODE_CWD': '/vscode/bin/linux-x64/f1a4fb101478ce6ec82fe9627c43efbf9e98c813',\n",
       "        'VSCODE_NLS_CONFIG': '{\"userLocale\":\"fr\",\"osLocale\":\"fr\",\"resolvedLanguage\":\"en\",\"defaultMessagesFile\":\"/vscode/bin/linux-x64/f1a4fb101478ce6ec82fe9627c43efbf9e98c813/out/nls.messages.json\",\"locale\":\"fr\",\"availableLanguages\":{}}',\n",
       "        'VSCODE_HANDLES_SIGPIPE': 'true',\n",
       "        'VSCODE_ESM_ENTRYPOINT': 'vs/workbench/api/node/extensionHostProcess',\n",
       "        'VSCODE_HANDLES_UNCAUGHT_ERRORS': 'true',\n",
       "        'BROWSER': '/vscode/bin/linux-x64/f1a4fb101478ce6ec82fe9627c43efbf9e98c813/bin/helpers/browser.sh',\n",
       "        'ELECTRON_RUN_AS_NODE': '1',\n",
       "        'VSCODE_IPC_HOOK_CLI': '/tmp/vscode-ipc-cebca878-3915-4cc4-b924-23e5ea6ef14d.sock',\n",
       "        'APPLICATION_INSIGHTS_NO_DIAGNOSTIC_CHANNEL': '1',\n",
       "        'VSCODE_L10N_BUNDLE_LOCATION': 'vscode-local:/c%3A/Users/MSI/.vscode/extensions/ms-ceintl.vscode-language-pack-fr-1.95.2024103009/translations/extensions/vscode.markdown-language-features.i18n.json',\n",
       "        'PYTHONUNBUFFERED': '1',\n",
       "        'CONDA_EXE': '/opt/conda/bin/conda',\n",
       "        '_CE_M': '',\n",
       "        'CONDA_ROOT': '/opt/conda',\n",
       "        'CONDA_PREFIX': '/opt/conda/envs/mini_rag',\n",
       "        'CONDA_PROMPT_MODIFIER': '(mini_rag) ',\n",
       "        '_CE_CONDA': '',\n",
       "        'CONDA_SHLVL': '2',\n",
       "        'CONDA_PYTHON_EXE': '/opt/conda/bin/python',\n",
       "        'CONDA_DEFAULT_ENV': 'mini_rag',\n",
       "        'CONDA_PREFIX_1': '/opt/conda',\n",
       "        'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING': '1',\n",
       "        'PYTHON_FROZEN_MODULES': 'on',\n",
       "        'PYDEVD_USE_FRAME_EVAL': 'NO',\n",
       "        'TERM': 'xterm-color',\n",
       "        'CLICOLOR': '1',\n",
       "        'FORCE_COLOR': '1',\n",
       "        'CLICOLOR_FORCE': '1',\n",
       "        'PAGER': 'cat',\n",
       "        'GIT_PAGER': 'cat',\n",
       "        'MPLBACKEND': 'module://matplotlib_inline.backend_inline'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Gentle Introduction to RAG Applications\n",
    "\n",
    "This notebook creates a simple RAG (Retrieval-Augmented Generation) system to answer questions from a PDF document using an open-source model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mini_rag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/codespace/.cache/huggingface/hub\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "# Get the default cache directory\n",
    "from transformers import TRANSFORMERS_CACHE\n",
    "\n",
    "print(TRANSFORMERS_CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/codespace/.cache/torch/hub\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check default directory where models are saved\n",
    "print(torch.hub.get_dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/codespace/.cache/huggingface/transformers/\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "print(os.path.expanduser('~/.cache/huggingface/transformers/'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_FILE = \"FAQ_GDG.pdf\"\n",
    "\n",
    "# We'll be using Llama 3.1 8B for this example.\n",
    "MODEL = \"llama3.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the PDF document\n",
    "\n",
    "starting by loading the PDF document and breaking it down into separate pages.\n",
    "\n",
    "<img src='images/documents.png' width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pypdf in c:\\users\\msi\\miniconda3\\envs\\gn\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\users\\msi\\appdata\\roaming\\python\\python310\\site-packages (from pypdf) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 12\n",
      "Length of a page: 2000\n",
      "Content of a page: W h y\n",
      "w a s\n",
      "m y\n",
      "a c c o u n t\n",
      "t u r n e d\n",
      "t o\n",
      "p r i v a t e ?\n",
      "If\n",
      "we\n",
      "r easonably\n",
      "belie v e\n",
      "content\n",
      "in\n",
      "y our\n",
      "pr oﬁle\n",
      "violates\n",
      "our\n",
      "content\n",
      "policy\n",
      ",\n",
      "y our\n",
      "account\n",
      "will\n",
      "be\n",
      "switched\n",
      "t o\n",
      "priv ate\n",
      "and\n",
      "the\n",
      "content\n",
      "in\n",
      "y our\n",
      "pr oﬁle\n",
      "will\n",
      "be\n",
      "deleted.\n",
      "Y ou\n",
      "won 't\n",
      "be\n",
      "able\n",
      "t o\n",
      "mak e\n",
      "y our\n",
      "account\n",
      "public\n",
      "again\n",
      "for\n",
      "at\n",
      "least\n",
      "60\n",
      "da ys.\n",
      "Google\n",
      "also\n",
      "r eser v es\n",
      "the\n",
      "right\n",
      "t o\n",
      "suspend\n",
      "or\n",
      "terminate\n",
      "y our\n",
      "access\n",
      "t o\n",
      "the\n",
      "ser vices\n",
      "or\n",
      "delete\n",
      "y our\n",
      "Google\n",
      "Account,\n",
      "as\n",
      "described\n",
      "in\n",
      "the\n",
      "T aking\n",
      "action\n",
      "in\n",
      "case\n",
      "of\n",
      "pr oblems\n",
      "section\n",
      "of\n",
      "the\n",
      "Google\n",
      "T erms\n",
      "of\n",
      "Ser vice.\n",
      "W h a t\n",
      "h a p p e n s\n",
      "w h e n\n",
      "I\n",
      "i n t e g r a t e\n",
      "m y\n",
      "p r o ﬁ l e\n",
      "w i t h\n",
      "a\n",
      "t h i r d - p a r t y\n",
      "a p p\n",
      "o r\n",
      "s e r v i c e ?\n",
      "If\n",
      "y ou\n",
      "authoriz e\n",
      "an\n",
      "application\n",
      "t o\n",
      "access\n",
      "y our\n",
      "Google\n",
      "De v eloper\n",
      "Pr ogr am\n",
      "pr oﬁle,\n",
      "that\n",
      "application\n",
      "will\n",
      "be\n",
      "able\n",
      "t o\n",
      "see\n",
      "y our\n",
      "pr oﬁle\n",
      "information,\n",
      "e v en\n",
      "if\n",
      "y ou\n",
      "ha v e\n",
      "not\n",
      "made\n",
      "y our\n",
      "pr oﬁle\n",
      "public.\n",
      "Learn\n",
      "mor e\n",
      "about\n",
      "how\n",
      "t o\n",
      "manage\n",
      "thir d-par ty\n",
      "apps\n",
      "and\n",
      "ser vices\n",
      "with\n",
      "access\n",
      "t o\n",
      "y our\n",
      "account.\n",
      "C a n\n",
      "I\n",
      "t r a n s f e r\n",
      "o r\n",
      "m e r g e\n",
      "m y\n",
      "a c c o u n t\n",
      "w i t h\n",
      "a n o t h e r\n",
      "p r o ﬁ l e ?\n",
      "Y ou\n",
      "cannot\n",
      "tr ansf er\n",
      "or\n",
      "mer ge\n",
      "y our\n",
      "pr oﬁle\n",
      "with\n",
      "another\n",
      "account.\n",
      "It' s\n",
      "encour aged\n",
      "t o\n",
      "use\n",
      "y our\n",
      "personal\n",
      "account\n",
      "(when\n",
      "appr opriate)\n",
      "for\n",
      "y our\n",
      "Google\n",
      "De v eloper\n",
      "Pr ogr am\n",
      "pr oﬁle\n",
      "t o\n",
      "ensur e\n",
      "y ou\n",
      "r etain\n",
      "all\n",
      "the\n",
      "badges\n",
      "and\n",
      "information.\n",
      "W h y\n",
      "c a n ' t\n",
      "I\n",
      "c r e a t e\n",
      "a\n",
      "p r o ﬁ l e\n",
      "w i t h\n",
      "m y\n",
      "G o o g l e\n",
      "W o r k s p a c e\n",
      "a c c o u n t ?\n",
      "The\n",
      "Google\n",
      "De v eloper\n",
      "Pr ogr am\n",
      "pr oﬁle\n",
      "suppor ts\n",
      "Google\n",
      "W orkspace\n",
      "account\n",
      "types;\n",
      "howe v er ,\n",
      "if\n",
      "y ou\n",
      "ar e\n",
      "getting\n",
      "an\n",
      "err or\n",
      "y ou\n",
      "might\n",
      "need\n",
      "y our\n",
      "or ganization ' s\n",
      "administr at or\n",
      "t o\n",
      "enable\n",
      "access\n",
      "t o\n",
      "the\n",
      "Google\n",
      "De v elopers\n",
      "ser vice.\n",
      "F or\n",
      "mor e\n",
      "information,\n",
      "see\n",
      "T urn\n",
      "Google\n",
      "De v elopers\n",
      "on\n",
      "or\n",
      "off\n",
      "for\n",
      "users\n",
      ".\n",
      "W h e r e\n",
      "s h o u l d\n",
      "I\n",
      "ﬁ l e\n",
      "i s s u e s\n",
      "o r\n",
      "f e e d b a c k ?\n",
      "If\n",
      "y ou\n",
      "encounter\n",
      "any\n",
      "issues\n",
      "or\n",
      "want\n",
      "t o\n",
      "pr o vide\n",
      "f eedback\n",
      "on\n",
      "anything\n",
      "r elated\n",
      "t o\n",
      "y our\n",
      "Google\n",
      "De v eloper\n",
      "Pr ogr am\n",
      "pr oﬁle,\n",
      "click\n",
      "Send\n",
      "F eedback\n",
      "at\n",
      "the\n",
      "bott om\n",
      "of\n",
      "y our\n",
      "Google\n",
      "De v eloper\n",
      "Pr ogr am\n",
      "pr oﬁle\n",
      "page\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(PDF_FILE)\n",
    "pages = loader.load()\n",
    "\n",
    "print(f\"Number of pages: {len(pages)}\")\n",
    "print(f\"Length of a page: {len(pages[1].page_content)}\")\n",
    "print(\"Content of a page:\", pages[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the pages in chunks\n",
    "\n",
    "Pages are too long, so let's split pages into different chunks.\n",
    "\n",
    "<img src='images/splitter.png' width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 33\n",
      "Length of a chunk: 693\n",
      "Content of a chunk: b y\n",
      "going\n",
      "t o\n",
      "de v elopers.google.com/pr oﬁle/u/me\n",
      ".\n",
      "H o w\n",
      "d o\n",
      "I\n",
      "e d i t\n",
      "m y\n",
      "p r o ﬁ l e ?\n",
      "Y ou\n",
      "can\n",
      "edit\n",
      "y our\n",
      "Google\n",
      "De v eloper\n",
      "Pr ogr am\n",
      "pr oﬁle\n",
      "b y\n",
      "going\n",
      "t o\n",
      "de v elopers.google.com/pr oﬁle/u/me\n",
      ".\n",
      "W h a t\n",
      "h a p p e n s\n",
      "i f\n",
      "I\n",
      "m a k e\n",
      "m y\n",
      "p r o ﬁ l e\n",
      "p u b l i c ?\n",
      "Making\n",
      "y our\n",
      "pr oﬁle\n",
      "public\n",
      "mak es\n",
      "it\n",
      "viewable\n",
      "b y\n",
      "any one\n",
      "online.\n",
      "This\n",
      "includes\n",
      "y our\n",
      "name,\n",
      "image,\n",
      "r ole,\n",
      "company\n",
      "or\n",
      "school,\n",
      "bio,\n",
      "badges\n",
      "y ou'v e\n",
      "r eceiv ed,\n",
      "stats,\n",
      "and\n",
      "y our\n",
      "social\n",
      "media\n",
      "links\n",
      "(including\n",
      "GitHub,\n",
      "GitLab,\n",
      "X,\n",
      "Link edIn,\n",
      "and\n",
      "Stack\n",
      "Ov erﬂow).\n",
      "Y our\n",
      "pages\n",
      "sa v ed,\n",
      "pages\n",
      "r ated,\n",
      "and\n",
      "e v ents\n",
      "attended\n",
      "ar e\n",
      "not\n",
      "par t\n",
      "of\n",
      "y our\n",
      "public\n",
      "pr oﬁle.\n",
      "Y ou\n",
      "can\n",
      "change\n",
      "y our\n",
      "pr oﬁle\n",
      "priv acy\n",
      "settings\n",
      "under\n",
      "the\n",
      "Account\n",
      "tab\n",
      "at\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=100)\n",
    "\n",
    "chunks = splitter.split_documents(pages)\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "print(f\"Length of a chunk: {len(chunks[1].page_content)}\")\n",
    "print(\"Content of a chunk:\", chunks[1].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the chunks in a vector store\n",
    "\n",
    "We can now generate embeddings for every chunk and store them in a vector store.\n",
    "we will use FAISS: Facebook AI Similarity Search\n",
    "\n",
    "<img src='images/vectorstore.png' width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-community faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "print(faiss.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\miniconda3\\envs\\gn\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "ST = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\")\n",
    "query= \"hello \"\n",
    "embedded_query = ST.encode(query)\n",
    "embedded_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embedded_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "#from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings # new lib\n",
    "\n",
    "embed_model = \"nomic-embed-text\" # we can use same embed model as llama3.1 as they came in pairs\n",
    "embeddings = OllamaEmbeddings(model=embed_model)\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a retriever\n",
    "\n",
    "We can use a retriever to find chunks in the vector store that are similar to a supplied question.\n",
    "\n",
    "<img src='images/retriever1.png' width=\"1000\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'FAQ_GDG.pdf', 'page': 9}, page_content='GDSC\\nFAQ\\nThe\\npurpose\\nof\\nthis\\ndocument\\nis\\nto\\ncapture\\nfrequently\\nasked\\nquestions\\nabout\\nthe\\nGDSC\\nprogram.\\nJoin\\nGDSC\\nWho\\nshould\\njoin\\nGoogle\\nDeveloper\\nStudent\\nClubs?\\nCollege\\nand\\nuniv ersity\\nstudents\\nar e\\nencour aged\\nt o\\njoin\\nGoogle\\nDe v eloper\\nStudent\\nClubs.\\nCan\\nI\\njoin\\nmultiple\\nchapters?\\nY ou\\ncan\\npar ticipate\\nin\\ne v ents\\nor ganiz ed\\nb y\\nmultiple\\nchapters,\\nhowe v er\\nif\\ny ou\\ndecide\\nt o\\ndedicate\\ny ourself\\nt o\\nbecome\\na\\nGDSC\\nLead\\nor\\nCor e\\nT eam\\nMember ,\\ny ou\\nwill\\nbe\\noﬃcially\\nassigned\\nt o\\none\\nchapter .\\nWhat\\ndoes\\na\\nGDSC\\nlead\\ndo?\\nIn\\ngener al,\\nGDSC\\nleaders\\nar e\\nfocused\\non\\nthe\\nfollowing\\nar eas:\\n●\\nStar t\\na\\nclub\\n-\\nW ork\\nwith\\ny our\\nuniv ersity\\nor\\ncollege\\nt o\\nstar t\\na\\nstudent\\nclub.\\nSelect\\na\\ncor e\\nteam\\nand'),\n",
       " Document(metadata={'source': 'FAQ_GDG.pdf', 'page': 10}, page_content=\"Lead\\napplication\\n.\\n●\\nW e 'll\\nr e view\\ny our\\nsubmission\\nand\\nget\\nback\\nt o\\ny ou\\nvia\\nemail\\nas\\nsoon\\nas\\npossible.\\nBenefits\\nWhat\\nare\\nthe\\nbenefits\\nof\\nbecoming\\na\\nGDSC\\nlead?\"),\n",
       " Document(metadata={'source': 'FAQ_GDG.pdf', 'page': 11}, page_content='GDSC\\nLeads\\nshould\\nbe\\na v ailable\\nt o\\nrun\\nan\\ne v ent\\nideally\\nonce\\na\\nmonth,\\nand\\nat\\nleast\\ne v er y\\nthr ee\\nmonths\\nt o\\nr emain\\nan\\nactiv e\\nGDSC\\nchapter .\\nAdditionally ,\\nrunning\\na\\nGDSC\\nis\\na\\none\\ny ear\\ncommitment.\\nTimeline\\nWhat\\nis\\nthe\\ntimeline\\nfor\\napplying\\nfor\\nthe\\nGDSC\\nLead\\nposition?\\nW e\\naccept\\napplications\\nonce\\nper\\ny ear ,\\nbetween\\nApril\\nand\\nA ugust.\\nPlease\\nfollow\\nthis\\npage\\nfor\\nthe\\nnew\\ndeadlines\\nand\\nthe\\nGDSC\\ne v ents\\nplatform\\nt o\\ncheck\\ncurr ent\\nchapters.'),\n",
       " Document(metadata={'source': 'FAQ_GDG.pdf', 'page': 11}, page_content='Ther e\\nar e\\na\\nnumber\\nof\\nbeneﬁts\\nt o\\nleading\\na\\nGDSC\\nchapter ,\\nbut\\nher e\\nar e\\na\\nf ew\\nthat\\nstand\\nout:\\n●\\nPr of essional\\ngr owth\\n-\\nAccess\\nt o\\ncommunity\\nmanagement\\ntr aining\\nand\\ntechnical\\nknowledge\\nt o\\nhelp\\ny ou\\nbe\\na\\nstr onger\\nleader ,\\nand\\nr eceiv e\\ninvitations\\nt o\\nselect\\nGoogle\\ne v ents.\\n●\\nNetwork\\ngr owth\\n-\\nAccess\\nt o\\na\\nglobal\\nnetwork\\nof\\nstudent\\nleaders,\\npr of essional\\ncommunity\\nor ganiz ers,\\nindustr y\\nexper ts,\\nand\\nGooglers\\nt o\\ngain\\nment orship\\nand\\nshar e\\nknowledge.\\n●\\nCommunity\\nlearning\\n-\\nDedicated\\nsuppor t\\nt o\\nhelp\\neducate\\nand\\nexpand\\ny our\\ncommunity\\nonline\\nand\\nin-person.\\nWhat\\nis\\nthe\\ntime\\ncommitment?\\nGDSC\\nLeads\\nshould\\nbe\\na v ailable\\nt o\\nrun\\nan\\ne v ent\\nideally\\nonce\\na\\nmonth,\\nand\\nat\\nleast\\ne v er y')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "retriever.invoke(\"what is GDSC ?\")\n",
    "# 4 k- similar chunks by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the model\n",
    "\n",
    "We'll be using Ollama to load the local model in memory. After creating the model, we can invoke it with a question to get the response back.\n",
    "\n",
    "<img src='images/model1.png' width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', 'docstore', 'document_loaders', 'utils', 'vectorstores']\n"
     ]
    }
   ],
   "source": [
    "import langchain_community\n",
    "print(dir(langchain_community))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As of my last update in April 2023, Joe Biden is the President of the United States. He took office on January 20, 2021, succeeding Donald Trump as the 46th President of the United States. Please note that this information might change over time due to elections or other political developments.', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2024-11-28T13:38:25.9847052Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 30240396900, 'load_duration': 17220478000, 'prompt_eval_count': 19, 'prompt_eval_duration': 2285017000, 'eval_count': 65, 'eval_duration': 10723552000}, id='run-e63e6834-903d-45cc-8a93-aa7bd0f88662-0', usage_metadata={'input_tokens': 19, 'output_tokens': 65, 'total_tokens': 84})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(model=MODEL, temperature=0)\n",
    "model.invoke(\"Who is the president of the United States?\") # eww whats is that \"AIMEssage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-groq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(\n",
    "    temperature=0,\n",
    "    model= \"llama-3.1-70b-versatile\",#MODEL\n",
    "    api_key=\"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\",\n",
    "    verbose= True,\n",
    "    max_retries=3,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the model's response\n",
    "\n",
    "The response from the model is an `AIMessage` instance containing the answer. We can extract the text answer by using the appropriate output parser. We can connect the model and the parser using a chain.\n",
    "\n",
    "<img src='images/parser1.png' width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunisia is a country located in North Africa. It is situated in the Maghreb region, bordered by:\n",
      "\n",
      "1. Algeria to the west\n",
      "2. Libya to the southeast\n",
      "3. Mediterranean Sea to the north and east\n",
      "\n",
      "Tunisia is a relatively small country, with a total area of approximately 163,610 square kilometers (63,170 square miles). Its capital and largest city is Tunis, which is located in the northeastern part of the country.\n",
      "\n",
      "Geographically, Tunisia is characterized by a diverse landscape, with mountains, deserts, and coastal plains. The country has a long coastline along the Mediterranean Sea, with several important ports, including the Port of Tunis and the Port of Sfax.\n",
      "\n",
      "Here's a rough outline of Tunisia's location:\n",
      "\n",
      "* Latitude: 30° - 38° N\n",
      "* Longitude: 7° - 12° E\n",
      "\n",
      "Tunisia is a strategic location, connecting Europe, Africa, and the Middle East, making it an important hub for trade, culture, and tourism.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = model | parser \n",
    "print(chain.invoke(\"where tunisia is located\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a prompt\n",
    "\n",
    "In addition to the question we want to ask, we also want to provide the model with the context from the PDF file. We can use a prompt template to define and reuse the prompt we'll use with the model.\n",
    "\n",
    "\n",
    "<img src='images/prompt1.png' width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an assistant that provides answers to questions based on\n",
      "a given context. \n",
      "\n",
      "Answer the question based on the context. If you can't answer the\n",
      "question, reply \"I don't know\".\n",
      "\n",
      "Be as concise as possible and go straight to the point.\n",
      "\n",
      "Context: Here is some context\n",
      "\n",
      "Question: Here is a question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are an assistant that provides answers to questions based on\n",
    "a given context. \n",
    "\n",
    "Answer the question based on the context. If you can't answer the\n",
    "question, reply \"I don't know\".\n",
    "\n",
    "Be as concise as possible and go straight to the point.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"Here is some context\", question=\"Here is a question\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the prompt to the chain\n",
    "\n",
    "We can now chain the prompt with the model and the parser.\n",
    "\n",
    "<img src='images/chain11.png' width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anna.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\n",
    "    \"context\": \"Anna's sister is Susan\", \n",
    "    \"question\": \"Who is Susan's sister?\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the retriever to the chain\n",
    "\n",
    "Finally, we can connect the retriever to the chain to get the context from the vector store.\n",
    "\n",
    "context is list of 4 most similar\n",
    "\n",
    "<img src='images/chain22.png' width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the chain to answer questions\n",
    "\n",
    "Finally, we can use the chain to ask questions that will be answered using the PDF document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is GDG ?\n",
      "Answer: The Google Developer Group offers tools and resources to help you on your development journey.\n",
      "*************************\n",
      "\n",
      "Question: What is GDSC ?\n",
      "Answer: GDSC stands for Google Developer Student Clubs.\n",
      "*************************\n",
      "\n",
      "Question: What is GDE?\n",
      "Answer: GDE stands for Google Developer Experts.\n",
      "*************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"What is GDG ?\",\n",
    "    \"What is GDSC ?\",\n",
    "    \"What is GDE?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {chain.invoke({'question': question})}\")\n",
    "    print(\"*************************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q= \"how many members in GDG carthage ? \"\n",
    "\n",
    "chain.invoke({'question': q})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To join GDG: Visit the members site at https://gdg.community.dev/ and join a chapter or apply to create a new chapter if none exists in your area.\\n\\nTo become a GDE: You need to have solid expertise in an area featuring Google technology, be passionate about giving back to the community, and meet the eligibility criteria.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q= \"how can i join GDG and be a GDE \"\n",
    "chain.invoke({'question': q})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, there is no cost to join a chapter or attend events.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q= \"do i need to pay any fees to be a member in GDG and attend workshops ? \"\n",
    "\n",
    "chain.invoke({'question': q})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What to do next ? \n",
    "\n",
    "Play with the size of chunks\n",
    "\n",
    "Try different documents \n",
    "\n",
    "Try multiple documents not just one.\n",
    "\n",
    "Different model other than llama3.1 \n",
    "\n",
    "Try different embedding models.\n",
    "\n",
    "Try different vectorstore databases\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_ubuntu",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
